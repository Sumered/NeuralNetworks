{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WDL2beta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRxNPYiBenr0",
        "colab_type": "code",
        "outputId": "6a474226-b7ca-4078-f6c9-41ce4cb2f4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI91yVh2ewIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = tfds.load('cats_vs_dogs',split = 'train[:80%]',as_supervised = True)\n",
        "val_set = tfds.load('cats_vs_dogs',split = 'train[80%:90%]',as_supervised = True)\n",
        "test_set = tfds.load('cats_vs_dogs',split = 'train[90%:]',as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SArBoQ0Ve-xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Buffer_size = 10000\n",
        "batch_size = 32\n",
        "def scale(image,label):\n",
        "    image = tf.cast(image,tf.float32)\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.resize(image,[150,150])\n",
        "    image /=255\n",
        "    return image,label\n",
        "\n",
        "train_set = train_set.map(scale).cache().shuffle(Buffer_size).batch(batch_size)\n",
        "test_set = test_set.map(scale).cache().shuffle(Buffer_size).batch(batch_size)\n",
        "val_set = val_set.map(scale).cache().shuffle(Buffer_size).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-3qAqy6fMZ5",
        "colab_type": "code",
        "outputId": "9bbd46a5-882d-49a2-f049-ab8a4913506e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = Sequential(name = \"model1\")\n",
        "model1.add(Flatten(input_shape=(150,150,1)))\n",
        "model1.add(Dense(256,activation='tanh'))\n",
        "model1.add(Dense(128,activation='tanh'))\n",
        "model1.add(Dense(2,activation='softmax'))\n",
        "\n",
        "adam_fine = Adam(lr = 0.0001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "model1.compile(optimizer= adam_fine,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
        "tensorboard1 = TensorBoard('logs/mlp-model1')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "model1_checkpoint = ModelCheckpoint('model1.h5', save_best_only=True)\n",
        "\n",
        "model1.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, model1_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.7008 - accuracy: 0.5496 - val_loss: 0.6965 - val_accuracy: 0.4914 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6791 - accuracy: 0.5661 - val_loss: 0.6762 - val_accuracy: 0.5821 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6723 - accuracy: 0.5856 - val_loss: 0.6654 - val_accuracy: 0.6062 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6691 - accuracy: 0.5882 - val_loss: 0.6674 - val_accuracy: 0.6088 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6681 - accuracy: 0.5941 - val_loss: 0.6636 - val_accuracy: 0.6032 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6663 - accuracy: 0.5943 - val_loss: 0.6568 - val_accuracy: 0.6191 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 25s 44ms/step - loss: 0.6632 - accuracy: 0.5966 - val_loss: 0.6764 - val_accuracy: 0.6105 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.5981\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6646 - accuracy: 0.5981 - val_loss: 0.6639 - val_accuracy: 0.6088 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6571 - accuracy: 0.6168 - val_loss: 0.6558 - val_accuracy: 0.6247 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6526 - accuracy: 0.6193 - val_loss: 0.6542 - val_accuracy: 0.6191 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6502 - accuracy: 0.6222 - val_loss: 0.6542 - val_accuracy: 0.6165 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6480 - accuracy: 0.6215 - val_loss: 0.6526 - val_accuracy: 0.6221 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6458 - accuracy: 0.6265 - val_loss: 0.6512 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6446 - accuracy: 0.6270 - val_loss: 0.6486 - val_accuracy: 0.6225 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6419 - accuracy: 0.6308 - val_loss: 0.6507 - val_accuracy: 0.6217 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6390 - accuracy: 0.6345\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6389 - accuracy: 0.6345 - val_loss: 0.6503 - val_accuracy: 0.6126 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6340 - accuracy: 0.6380 - val_loss: 0.6482 - val_accuracy: 0.6255 - lr: 1.0000e-06\n",
            "Epoch 18/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6328 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6247 - lr: 1.0000e-06\n",
            "Epoch 19/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6322 - accuracy: 0.6414 - val_loss: 0.6476 - val_accuracy: 0.6251 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6318 - accuracy: 0.6409 - val_loss: 0.6472 - val_accuracy: 0.6247 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6312 - accuracy: 0.6415 - val_loss: 0.6473 - val_accuracy: 0.6238 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6309 - accuracy: 0.6414\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6309 - accuracy: 0.6414 - val_loss: 0.6480 - val_accuracy: 0.6268 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6302 - accuracy: 0.6413 - val_loss: 0.6483 - val_accuracy: 0.6260 - lr: 1.0000e-07\n",
            "Epoch 24/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6301 - accuracy: 0.6415\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6300 - accuracy: 0.6418 - val_loss: 0.6477 - val_accuracy: 0.6255 - lr: 1.0000e-07\n",
            "Epoch 25/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6300 - accuracy: 0.6414 - val_loss: 0.6471 - val_accuracy: 0.6255 - lr: 1.0000e-08\n",
            "Epoch 26/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.6415\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6300 - accuracy: 0.6415 - val_loss: 0.6476 - val_accuracy: 0.6247 - lr: 1.0000e-08\n",
            "Epoch 27/30\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6299 - accuracy: 0.6415 - val_loss: 0.6474 - val_accuracy: 0.6247 - lr: 1.0000e-09\n",
            "Epoch 28/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.6416\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6299 - accuracy: 0.6416 - val_loss: 0.6472 - val_accuracy: 0.6247 - lr: 1.0000e-09\n",
            "Epoch 29/30\n",
            "582/582 [==============================] - 25s 42ms/step - loss: 0.6299 - accuracy: 0.6416 - val_loss: 0.6470 - val_accuracy: 0.6247 - lr: 1.0000e-10\n",
            "Epoch 30/30\n",
            "582/582 [==============================] - 25s 43ms/step - loss: 0.6299 - accuracy: 0.6416 - val_loss: 0.6484 - val_accuracy: 0.6247 - lr: 1.0000e-10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f993d66fc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNZFc3SSgILT",
        "colab_type": "code",
        "outputId": "bc95577f-5088-4189-cfa0-b19f8e3604db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model2 = Sequential([\n",
        "    Flatten(input_shape=(150, 150, 1)),\n",
        "    Dense(128, activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.0001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "model2.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-model2')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "model2_checkpoint = ModelCheckpoint('model2.h5', save_best_only=True)\n",
        "\n",
        "model2.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, model2_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.7053 - accuracy: 0.5617 - val_loss: 0.6691 - val_accuracy: 0.5993 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6714 - accuracy: 0.5829 - val_loss: 0.6628 - val_accuracy: 0.6036 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6695 - accuracy: 0.5881 - val_loss: 0.6644 - val_accuracy: 0.6062 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6643 - accuracy: 0.5975 - val_loss: 0.6602 - val_accuracy: 0.6139 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6618 - accuracy: 0.6072 - val_loss: 0.6721 - val_accuracy: 0.5787 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6604 - accuracy: 0.6085\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6605 - accuracy: 0.6084 - val_loss: 0.6690 - val_accuracy: 0.5976 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6538 - accuracy: 0.6189 - val_loss: 0.6590 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6500 - accuracy: 0.6260 - val_loss: 0.6606 - val_accuracy: 0.6152 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6476 - accuracy: 0.6238 - val_loss: 0.6576 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6452 - accuracy: 0.6258 - val_loss: 0.6573 - val_accuracy: 0.6174 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6433 - accuracy: 0.6268 - val_loss: 0.6539 - val_accuracy: 0.6148 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6407 - accuracy: 0.6307 - val_loss: 0.6539 - val_accuracy: 0.6264 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "582/582 [==============================] - 13s 23ms/step - loss: 0.6385 - accuracy: 0.6303 - val_loss: 0.6527 - val_accuracy: 0.6225 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6356 - accuracy: 0.6357 - val_loss: 0.6514 - val_accuracy: 0.6212 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6329 - accuracy: 0.6375 - val_loss: 0.6505 - val_accuracy: 0.6277 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6297 - accuracy: 0.6399 - val_loss: 0.6522 - val_accuracy: 0.6187 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "580/582 [============================>.] - ETA: 0s - loss: 0.6271 - accuracy: 0.6441\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6272 - accuracy: 0.6443 - val_loss: 0.6509 - val_accuracy: 0.6217 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6204 - accuracy: 0.6535 - val_loss: 0.6461 - val_accuracy: 0.6268 - lr: 1.0000e-06\n",
            "Epoch 19/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6192 - accuracy: 0.6529 - val_loss: 0.6461 - val_accuracy: 0.6285 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6187 - accuracy: 0.6535 - val_loss: 0.6457 - val_accuracy: 0.6290 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6182 - accuracy: 0.6532 - val_loss: 0.6472 - val_accuracy: 0.6281 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6570\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6177 - accuracy: 0.6570 - val_loss: 0.6469 - val_accuracy: 0.6285 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6169 - accuracy: 0.6566 - val_loss: 0.6462 - val_accuracy: 0.6285 - lr: 1.0000e-07\n",
            "Epoch 24/30\n",
            "580/582 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.6571\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "582/582 [==============================] - 13s 22ms/step - loss: 0.6168 - accuracy: 0.6570 - val_loss: 0.6461 - val_accuracy: 0.6273 - lr: 1.0000e-07\n",
            "Epoch 00024: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f993d833400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMoQ5tctuzw",
        "colab_type": "code",
        "outputId": "1f76cfc6-665d-48e4-c300-14a170e8707d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "model3 = Sequential([\n",
        "    Flatten(input_shape=(150, 150, 1)),\n",
        "    Dense(128, activation='tanh'),\n",
        "    Dense(64,activation = 'tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "model3.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-model3')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "model3_checkpoint = ModelCheckpoint('model3.h5', save_best_only=True)\n",
        "\n",
        "model3.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, model3_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 14s 24ms/step - loss: 0.7145 - accuracy: 0.5037 - val_loss: 0.6966 - val_accuracy: 0.5185 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 13s 23ms/step - loss: 0.6952 - accuracy: 0.5005 - val_loss: 0.6935 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 13s 23ms/step - loss: 0.6957 - accuracy: 0.4993 - val_loss: 0.6924 - val_accuracy: 0.5185 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 13s 23ms/step - loss: 0.6951 - accuracy: 0.5009 - val_loss: 0.6926 - val_accuracy: 0.5185 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "580/582 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5055\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 13s 23ms/step - loss: 0.6947 - accuracy: 0.5054 - val_loss: 0.7095 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 14s 23ms/step - loss: 0.6939 - accuracy: 0.4967 - val_loss: 0.6928 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4925\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 14s 23ms/step - loss: 0.6935 - accuracy: 0.4925 - val_loss: 0.6929 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f993de89a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjubsG4PukxB",
        "colab_type": "code",
        "outputId": "abbf924f-e126-40cd-e66a-592ea4983d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model4 = Sequential([\n",
        "    Flatten(input_shape=(150, 150, 1)),\n",
        "    Dense(128, activation='tanh'),\n",
        "    Dense(256,activation='tanh'),\n",
        "    Dense(512,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.0001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "model4.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-model4')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "model4_checkpoint = ModelCheckpoint('model4.h5', save_best_only=True)\n",
        "\n",
        "model4.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, model4_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6995 - accuracy: 0.5254 - val_loss: 0.6794 - val_accuracy: 0.5817 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6824 - accuracy: 0.5667 - val_loss: 0.6973 - val_accuracy: 0.5254 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6756 - accuracy: 0.5793 - val_loss: 0.6725 - val_accuracy: 0.5959 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6714 - accuracy: 0.5872 - val_loss: 0.6678 - val_accuracy: 0.5972 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6695 - accuracy: 0.5966 - val_loss: 0.6658 - val_accuracy: 0.6010 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6716 - accuracy: 0.5866 - val_loss: 0.6837 - val_accuracy: 0.4807 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "581/582 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5829\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6745 - accuracy: 0.5828 - val_loss: 0.6718 - val_accuracy: 0.5950 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6607 - accuracy: 0.6117 - val_loss: 0.6610 - val_accuracy: 0.6191 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6567 - accuracy: 0.6199 - val_loss: 0.6623 - val_accuracy: 0.6126 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6553 - accuracy: 0.6188 - val_loss: 0.6591 - val_accuracy: 0.6156 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6529 - accuracy: 0.6206 - val_loss: 0.6548 - val_accuracy: 0.6191 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6486 - accuracy: 0.6247 - val_loss: 0.6590 - val_accuracy: 0.6199 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6468 - accuracy: 0.6272 - val_loss: 0.6528 - val_accuracy: 0.6165 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6444 - accuracy: 0.6287 - val_loss: 0.6530 - val_accuracy: 0.6212 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.6337\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6413 - accuracy: 0.6337 - val_loss: 0.6534 - val_accuracy: 0.6187 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6370 - accuracy: 0.6375 - val_loss: 0.6523 - val_accuracy: 0.6212 - lr: 1.0000e-06\n",
            "Epoch 17/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6357 - accuracy: 0.6383 - val_loss: 0.6513 - val_accuracy: 0.6225 - lr: 1.0000e-06\n",
            "Epoch 18/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6349 - accuracy: 0.6385 - val_loss: 0.6509 - val_accuracy: 0.6234 - lr: 1.0000e-06\n",
            "Epoch 19/30\n",
            "582/582 [==============================] - 16s 27ms/step - loss: 0.6344 - accuracy: 0.6384 - val_loss: 0.6520 - val_accuracy: 0.6217 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6338 - accuracy: 0.6402 - val_loss: 0.6494 - val_accuracy: 0.6217 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6334 - accuracy: 0.6412 - val_loss: 0.6506 - val_accuracy: 0.6234 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "580/582 [============================>.] - ETA: 0s - loss: 0.6330 - accuracy: 0.6406\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6329 - accuracy: 0.6406 - val_loss: 0.6500 - val_accuracy: 0.6255 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "582/582 [==============================] - 16s 28ms/step - loss: 0.6320 - accuracy: 0.6418 - val_loss: 0.6508 - val_accuracy: 0.6242 - lr: 1.0000e-07\n",
            "Epoch 24/30\n",
            "580/582 [============================>.] - ETA: 0s - loss: 0.6319 - accuracy: 0.6415\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "582/582 [==============================] - 17s 28ms/step - loss: 0.6319 - accuracy: 0.6414 - val_loss: 0.6500 - val_accuracy: 0.6242 - lr: 1.0000e-07\n",
            "Epoch 00024: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f993d7b1550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0AyhwXWvK5l",
        "colab_type": "code",
        "outputId": "b4aca6f1-fd0d-47a0-ad5b-c9a4d9cf9bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model5 = Sequential([\n",
        "    Flatten(input_shape=(150, 150, 1)),\n",
        "    Dense(512, activation='tanh'),\n",
        "    Dense(256,activation='tanh'),\n",
        "    Dense(128,activation='tanh'),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "model5.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-model5')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "model5_checkpoint = ModelCheckpoint('model5.h5', save_best_only=True)\n",
        "\n",
        "model5.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, model5_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.7009 - accuracy: 0.5036 - val_loss: 0.7029 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6959 - accuracy: 0.5054 - val_loss: 0.6927 - val_accuracy: 0.5185 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6951 - accuracy: 0.5037 - val_loss: 0.6946 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.4981\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6962 - accuracy: 0.4981 - val_loss: 0.6952 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6913 - accuracy: 0.5252 - val_loss: 0.6897 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6838 - accuracy: 0.5564 - val_loss: 0.6751 - val_accuracy: 0.5774 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6774 - accuracy: 0.5754 - val_loss: 0.6747 - val_accuracy: 0.5916 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6750 - accuracy: 0.5822 - val_loss: 0.6765 - val_accuracy: 0.5641 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6743 - accuracy: 0.5822 - val_loss: 0.6686 - val_accuracy: 0.5997 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6712 - accuracy: 0.5919 - val_loss: 0.6723 - val_accuracy: 0.5924 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.5948\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6697 - accuracy: 0.5948 - val_loss: 0.6695 - val_accuracy: 0.5929 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6661 - accuracy: 0.5962 - val_loss: 0.6677 - val_accuracy: 0.5942 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6638 - accuracy: 0.5988 - val_loss: 0.6701 - val_accuracy: 0.5950 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6635 - accuracy: 0.6000 - val_loss: 0.6646 - val_accuracy: 0.5959 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "582/582 [==============================] - 49s 85ms/step - loss: 0.6625 - accuracy: 0.6045 - val_loss: 0.6641 - val_accuracy: 0.6006 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "582/582 [==============================] - 49s 83ms/step - loss: 0.6616 - accuracy: 0.6035 - val_loss: 0.6676 - val_accuracy: 0.5933 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.6024\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6612 - accuracy: 0.6024 - val_loss: 0.6648 - val_accuracy: 0.6006 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6598 - accuracy: 0.6046 - val_loss: 0.6638 - val_accuracy: 0.6028 - lr: 1.0000e-06\n",
            "Epoch 19/30\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6595 - accuracy: 0.6045 - val_loss: 0.6631 - val_accuracy: 0.6006 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "582/582 [==============================] - 48s 83ms/step - loss: 0.6594 - accuracy: 0.6060 - val_loss: 0.6628 - val_accuracy: 0.6015 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "582/582 [==============================] - 48s 82ms/step - loss: 0.6592 - accuracy: 0.6060 - val_loss: 0.6629 - val_accuracy: 0.6015 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.6070\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6593 - accuracy: 0.6070 - val_loss: 0.6634 - val_accuracy: 0.6015 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6590 - accuracy: 0.6069 - val_loss: 0.6635 - val_accuracy: 0.6015 - lr: 1.0000e-07\n",
            "Epoch 24/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.6070\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "582/582 [==============================] - 49s 84ms/step - loss: 0.6590 - accuracy: 0.6070 - val_loss: 0.6634 - val_accuracy: 0.6015 - lr: 1.0000e-07\n",
            "Epoch 00024: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f992f5373c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFOw5rh_vcGw",
        "colab_type": "code",
        "outputId": "4e5d3ad5-2f48-44b5-abc4-1582bbb844a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "modelcnn_1 = Sequential([\n",
        "    Conv2D(64,kernel_size=(3,3),activation = 'relu',input_shape=(150,150,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "modelcnn_1.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-modelcnn_1')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "modelcnn_1_checkpoint = ModelCheckpoint('modelcnn_1.h5', save_best_only=True)\n",
        "\n",
        "modelcnn_1.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, modelcnn_1_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 702s 1s/step - loss: 0.6850 - accuracy: 0.5680 - val_loss: 0.6591 - val_accuracy: 0.6328 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 696s 1s/step - loss: 0.6380 - accuracy: 0.6389 - val_loss: 0.6316 - val_accuracy: 0.6531 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 696s 1s/step - loss: 0.5700 - accuracy: 0.7054 - val_loss: 0.5883 - val_accuracy: 0.6952 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 699s 1s/step - loss: 0.5073 - accuracy: 0.7522 - val_loss: 0.5680 - val_accuracy: 0.7094 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 696s 1s/step - loss: 0.4435 - accuracy: 0.7892 - val_loss: 0.5108 - val_accuracy: 0.7485 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 690s 1s/step - loss: 0.3862 - accuracy: 0.8226 - val_loss: 0.5402 - val_accuracy: 0.7502 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8576\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 691s 1s/step - loss: 0.3228 - accuracy: 0.8576 - val_loss: 0.5556 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - 695s 1s/step - loss: 0.2036 - accuracy: 0.9219 - val_loss: 0.6511 - val_accuracy: 0.7567 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9308\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 697s 1s/step - loss: 0.1788 - accuracy: 0.9308 - val_loss: 0.6885 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f993d4b9eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCdAWwEu72d4",
        "colab_type": "code",
        "outputId": "9d5da109-fc11-4b12-c68c-788656848961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "modelcnn_2 = Sequential([\n",
        "    Conv2D(64,kernel_size=(3,3),activation = 'relu',input_shape=(150,150,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "modelcnn_2.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-modelcnn_2')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "modelcnn_2_checkpoint = ModelCheckpoint('modelcnn_2.h5', save_best_only=True)\n",
        "\n",
        "modelcnn_2.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, modelcnn_2_checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 760s 1s/step - loss: 0.6354 - accuracy: 0.6341 - val_loss: 0.5909 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 719s 1s/step - loss: 0.5318 - accuracy: 0.7343 - val_loss: 0.5139 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 727s 1s/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7597 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 722s 1s/step - loss: 0.4232 - accuracy: 0.8050 - val_loss: 0.4797 - val_accuracy: 0.7803 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 733s 1s/step - loss: 0.3949 - accuracy: 0.8197 - val_loss: 0.4797 - val_accuracy: 0.7747 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 722s 1s/step - loss: 0.3627 - accuracy: 0.8366 - val_loss: 0.4619 - val_accuracy: 0.7979 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 722s 1s/step - loss: 0.3346 - accuracy: 0.8546 - val_loss: 0.4853 - val_accuracy: 0.7790 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.8614\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 720s 1s/step - loss: 0.3146 - accuracy: 0.8614 - val_loss: 0.4873 - val_accuracy: 0.7949 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 734s 1s/step - loss: 0.2381 - accuracy: 0.9039 - val_loss: 0.4926 - val_accuracy: 0.8027 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9116\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 735s 1s/step - loss: 0.2188 - accuracy: 0.9116 - val_loss: 0.5198 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54b74ec898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMvNQ4e2HM8p",
        "colab_type": "code",
        "outputId": "7a2c9d7c-2150-4abc-90e3-b5cf15f89a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "modelcnn_3 = Sequential([\n",
        "    Conv2D(64,kernel_size=(3,3),activation = 'relu',input_shape=(150,150,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(32,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "modelcnn_3.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-modelcnn_3')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "modelcnn_3_checkpoint = ModelCheckpoint('modelcnn_3.h5', save_best_only=True)\n",
        "\n",
        "modelcnn_3.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, modelcnn_3_checkpoint]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 694s 1s/step - loss: 0.6483 - accuracy: 0.6139 - val_loss: 0.6063 - val_accuracy: 0.6836 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 669s 1s/step - loss: 0.5566 - accuracy: 0.7145 - val_loss: 0.5425 - val_accuracy: 0.7266 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 665s 1s/step - loss: 0.4832 - accuracy: 0.7679 - val_loss: 0.5237 - val_accuracy: 0.7446 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 665s 1s/step - loss: 0.4195 - accuracy: 0.8057 - val_loss: 0.4987 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 666s 1s/step - loss: 0.3610 - accuracy: 0.8399 - val_loss: 0.5091 - val_accuracy: 0.7635 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.8762\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 663s 1s/step - loss: 0.2918 - accuracy: 0.8762 - val_loss: 0.5216 - val_accuracy: 0.7623 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 665s 1s/step - loss: 0.1779 - accuracy: 0.9385 - val_loss: 0.5536 - val_accuracy: 0.7709 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9481\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 660s 1s/step - loss: 0.1538 - accuracy: 0.9481 - val_loss: 0.5768 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fefc05def28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAgOcEylV_0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "43dbc2cb-0fe5-43f0-9be8-0025d09e6c95"
      },
      "source": [
        "modelcnn_4 = Sequential([\n",
        "    Conv2D(64,kernel_size=(3,3),activation = 'relu',input_shape=(150,150,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(32,activation='tanh'),\n",
        "    Dense(16,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "modelcnn_4.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-modelcnn_4')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "modelcnn_4_checkpoint = ModelCheckpoint('modelcnn_4.h5', save_best_only=True)\n",
        "\n",
        "modelcnn_4.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, modelcnn_4_checkpoint]\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 665s 1s/step - loss: 0.6305 - accuracy: 0.6372 - val_loss: 0.5633 - val_accuracy: 0.7124 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 661s 1s/step - loss: 0.5143 - accuracy: 0.7465 - val_loss: 0.5090 - val_accuracy: 0.7502 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 669s 1s/step - loss: 0.4483 - accuracy: 0.7862 - val_loss: 0.4765 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 667s 1s/step - loss: 0.4102 - accuracy: 0.8075 - val_loss: 0.4631 - val_accuracy: 0.7803 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 666s 1s/step - loss: 0.3656 - accuracy: 0.8346 - val_loss: 0.4758 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.8557\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 663s 1s/step - loss: 0.3280 - accuracy: 0.8557 - val_loss: 0.4815 - val_accuracy: 0.7782 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 663s 1s/step - loss: 0.2326 - accuracy: 0.9098 - val_loss: 0.4795 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9190\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 658s 1s/step - loss: 0.2076 - accuracy: 0.9190 - val_loss: 0.4874 - val_accuracy: 0.7885 - lr: 1.0000e-04\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fefbfc08dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPMjpVp7XcL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "8c8823cd-d703-4bac-f00b-d72b44398918"
      },
      "source": [
        "modelcnn_5 = Sequential([\n",
        "    Conv2D(64,kernel_size=(3,3),activation = 'relu',input_shape=(150,150,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(8,kernel_size=(3,3),activation = 'relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(64,activation='tanh'),\n",
        "    Dense(32,activation='tanh'),\n",
        "    Dense(32,activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "adam_fine = Adam(lr = 0.001,beta_1 = 0.9, beta_2 = 0.999,epsilon =1e-08,decay = 0.0)\n",
        "\n",
        "modelcnn_5.compile(optimizer= adam_fine,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
        "tensorboard1 = TensorBoard('logs/mlp-modelcnn_5')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2) \n",
        "modelcnn_5_checkpoint = ModelCheckpoint('modelcnn_5.h5', save_best_only=True)\n",
        "\n",
        "modelcnn_5.fit(\n",
        "    x = train_set, epochs=30, validation_data=val_set,\n",
        "    callbacks=[early_stopping, tensorboard1, reduce_lr, modelcnn_5_checkpoint]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "582/582 [==============================] - 668s 1s/step - loss: 0.6797 - accuracy: 0.5573 - val_loss: 0.6715 - val_accuracy: 0.5856 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "582/582 [==============================] - 664s 1s/step - loss: 0.6668 - accuracy: 0.5901 - val_loss: 0.6586 - val_accuracy: 0.6191 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.6333 - accuracy: 0.6436 - val_loss: 0.6071 - val_accuracy: 0.6745 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "582/582 [==============================] - 658s 1s/step - loss: 0.5775 - accuracy: 0.6971 - val_loss: 0.5765 - val_accuracy: 0.6960 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.5148 - accuracy: 0.7471 - val_loss: 0.4996 - val_accuracy: 0.7605 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "582/582 [==============================] - 657s 1s/step - loss: 0.4600 - accuracy: 0.7834 - val_loss: 0.4606 - val_accuracy: 0.7773 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.4342 - val_accuracy: 0.8009 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "582/582 [==============================] - 660s 1s/step - loss: 0.3883 - accuracy: 0.8270 - val_loss: 0.4336 - val_accuracy: 0.8091 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.3700 - accuracy: 0.8357 - val_loss: 0.4253 - val_accuracy: 0.8040 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "582/582 [==============================] - 657s 1s/step - loss: 0.3472 - accuracy: 0.8470 - val_loss: 0.5142 - val_accuracy: 0.7674 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8575\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "582/582 [==============================] - 658s 1s/step - loss: 0.3277 - accuracy: 0.8575 - val_loss: 0.5199 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "582/582 [==============================] - 662s 1s/step - loss: 0.2701 - accuracy: 0.8904 - val_loss: 0.4146 - val_accuracy: 0.8190 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "582/582 [==============================] - 657s 1s/step - loss: 0.2551 - accuracy: 0.8966 - val_loss: 0.4131 - val_accuracy: 0.8255 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.2491 - accuracy: 0.8984 - val_loss: 0.4158 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "582/582 [==============================] - 660s 1s/step - loss: 0.2426 - accuracy: 0.9026 - val_loss: 0.4130 - val_accuracy: 0.8306 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "582/582 [==============================] - 660s 1s/step - loss: 0.2384 - accuracy: 0.9066 - val_loss: 0.4214 - val_accuracy: 0.8237 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9068\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "582/582 [==============================] - 659s 1s/step - loss: 0.2330 - accuracy: 0.9068 - val_loss: 0.4255 - val_accuracy: 0.8255 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "582/582 [==============================] - 667s 1s/step - loss: 0.2236 - accuracy: 0.9131 - val_loss: 0.4263 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9135\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "582/582 [==============================] - 660s 1s/step - loss: 0.2229 - accuracy: 0.9135 - val_loss: 0.4251 - val_accuracy: 0.8267 - lr: 1.0000e-05\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fefbea5bb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWChXUg8XrdV",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "MLP is working much worse than Conv, but Conv needs more time to learn. In MLP case increasing size of network doesnt seem to be helping. But in Conv case it seems to be helping. Difference beetween MLP and CNN is huge, 20% of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ojk70dnheCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "c1573045-f099-4410-f0c0-badafba4adfe"
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/file2.zip /content/logs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/logs/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/events.out.tfevents.1587284057.d26a67e61a50.124.70803.v2 (deflated 81%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/d26a67e61a50.overview_page.pb (deflated 71%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/d26a67e61a50.trace.json.gz (deflated 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/d26a67e61a50.input_pipeline.pb (deflated 72%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/d26a67e61a50.tensorflow_stats.pb (deflated 75%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/plugins/profile/2020_04_19_08_14_40/d26a67e61a50.kernel_stats.pb (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/train/events.out.tfevents.1587284080.d26a67e61a50.profile-empty (deflated 10%)\n",
            "  adding: content/logs/mlp-modelcnn_3/validation/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_3/validation/events.out.tfevents.1587284772.d26a67e61a50.124.75335.v2 (deflated 54%)\n",
            "  adding: content/logs/mlp-modelcnn_4/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/d26a67e61a50.overview_page.pb (deflated 59%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/d26a67e61a50.trace.json.gz (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/d26a67e61a50.input_pipeline.pb (deflated 58%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/d26a67e61a50.tensorflow_stats.pb (deflated 74%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/plugins/profile/2020_04_19_09_43_57/d26a67e61a50.kernel_stats.pb (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/events.out.tfevents.1587289437.d26a67e61a50.profile-empty (deflated 5%)\n",
            "  adding: content/logs/mlp-modelcnn_4/train/events.out.tfevents.1587289434.d26a67e61a50.124.101901.v2 (deflated 91%)\n",
            "  adding: content/logs/mlp-modelcnn_4/validation/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_4/validation/events.out.tfevents.1587290101.d26a67e61a50.124.106502.v2 (deflated 53%)\n",
            "  adding: content/logs/mlp-modelcnn_5/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/d26a67e61a50.overview_page.pb (deflated 60%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/d26a67e61a50.trace.json.gz (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/d26a67e61a50.input_pipeline.pb (deflated 58%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/d26a67e61a50.tensorflow_stats.pb (deflated 74%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/plugins/profile/2020_04_19_11_12_38/d26a67e61a50.kernel_stats.pb (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/events.out.tfevents.1587294755.d26a67e61a50.124.133145.v2 (deflated 91%)\n",
            "  adding: content/logs/mlp-modelcnn_5/train/events.out.tfevents.1587294758.d26a67e61a50.profile-empty (deflated 5%)\n",
            "  adding: content/logs/mlp-modelcnn_5/validation/ (stored 0%)\n",
            "  adding: content/logs/mlp-modelcnn_5/validation/events.out.tfevents.1587295425.d26a67e61a50.124.137824.v2 (deflated 60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osqit9LWs_Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "388c11c8-094b-4e36-fd1d-1329caf968cc"
      },
      "source": [
        "files.download(\"/content/file2.zip\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5c87d35607ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/file2.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eBjuQ9vtE3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}